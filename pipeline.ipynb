{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20171,"status":"ok","timestamp":1733294007664,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"_rvCUcp99EeY","outputId":"78c23759-ae67-470d-bc2c-5082c09b3f06"},"outputs":[],"source":["!pip install --upgrade pip\n","!pip install pyyaml\n","!pip install ultralytics\n","!apt-get update && apt-get install libgl1-mesa-glx -y\n","\n","# pip installs to get YOLO working!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17352,"status":"ok","timestamp":1733294025147,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"AIj9Wqxm94a5","outputId":"9de46b66-7f49-430d-99dd-ac28d3e75b8a"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# mounting google drive so we can pull in the data and directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11275,"status":"ok","timestamp":1733294036414,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"mrA1dhmZ9KhO","outputId":"7e1efd87-569e-4d55-fcbc-e1002cdbe928"},"outputs":[],"source":["import pandas as pd\n","import os\n","import shutil\n","import yaml\n","from sklearn.model_selection import train_test_split\n","from ultralytics import YOLO\n","\n","# imports:\n","# shututil used for file operations\n","# yaml for YOLO config file\n","# sklearn to train test split\n","# ultralytics to run YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":324,"status":"ok","timestamp":1733293371605,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"Bfq4kZ8Q9LME"},"outputs":[],"source":["images_load = '/content/drive/My Drive/D144/people_drone_detection_data/images/images' # load in images\n","annotations_load = '/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format' # load in annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1733294351627,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"ach36CQ09MGZ"},"outputs":[],"source":["images = []\n","annotations = []\n","# initialization\n","\n","\n","# iterate over each file in images and annotation as a pair to create a dataframe with both aligned\n","for img_file in os.listdir(images_load):\n","    if img_file.endswith(\".jpg\"):\n","        image_name = os.path.splitext(img_file)[0]\n","        annotation_name = image_name + \".txt\"\n","        if os.path.exists(os.path.join(annotations_load, annotation_name)):\n","            images.append(os.path.join(images_load, img_file))\n","            annotations.append(os.path.join(annotations_load, annotation_name))\n","\n","\n","\n","df = pd.DataFrame({\"images\": images, \"annotations\": annotations}) # creating the dataframe of images and annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33HMdSdi9O4q"},"outputs":[],"source":["train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","train, val = train_test_split(train_df, test_size=0.4, random_state=42)\n","# train test splitting into train and test, and further splitting train into train and val to have train, val, test"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1471,"status":"ok","timestamp":1733294368817,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"SkbicYwL9QOt"},"outputs":[],"source":["# Create directories for annotation image pairings for train, test, val\n","os.makedirs(os.path.join(\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\", \"train\", \"images\"), exist_ok = True)\n","os.makedirs(os.path.join(\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\", \"train\", \"annotations\"), exist_ok = True)\n","os.makedirs(os.path.join(\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\", \"val\", \"images\"), exist_ok = True)\n","os.makedirs(os.path.join(\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\", \"val\", \"annotations\"), exist_ok = True)\n","os.makedirs(os.path.join(\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\", \"test\", \"images\"), exist_ok = True)\n","os.makedirs(os.path.join(\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\", \"test\", \"annotations\"), exist_ok = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15963,"status":"ok","timestamp":1733205859925,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"rv1YlQFQ9TyU","outputId":"34d80335-d58f-44f0-d098-eed1c7735ebe"},"outputs":[],"source":["# training set image/annotation allocation:\n","\n","images_dir_train = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/train/images\"\n","annotations_dir_train = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/train/annotations\"\n","\n","def update_filepath_train(df):\n","  # extract from df\n","    images = df[\"images\"]\n","    annotations = df[\"annotations\"]\n","\n","  # get filenames\n","    image_dest_end =  os.path.basename(images)\n","    annotations_dest_end = os.path.basename(annotations)\n","\n","  # set destination paths\n","    image_dest = os.path.join(images_dir_train, image_dest_end)\n","    annotations_dest = os.path.join(annotations_dir_train, annotations_dest_end)\n","\n","  # move to train\n","    shutil.move(images, image_dest)\n","    shutil.move(annotations, annotations_dest)\n","\n","print(\"start train\")\n","train2 = train.apply(update_filepath_train, axis = 1) # for each row in train\n","print(\"done train\")\n","\n","# validation set image/annotation allocation:\n","\n","images_dir_val = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/val/images\"\n","annotations_dir_val = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/val/annotations\"\n","\n","def update_filepath_val(df):\n","  # extract from df\n","    images = df[\"images\"]\n","    annotations = df[\"annotations\"]\n","\n","  # get filenames\n","    image_dest_end =  os.path.basename(images)\n","    annotations_dest_end = os.path.basename(annotations)\n","\n","  # set destination paths\n","    image_dest = os.path.join(images_dir_val, image_dest_end)\n","    annotations_dest = os.path.join(annotations_dir_val, annotations_dest_end)\n","\n","  # move to val\n","    shutil.move(images, image_dest)\n","    shutil.move(annotations, annotations_dest)\n","\n","print(\"start val\")\n","val2 = val.apply(update_filepath_val, axis = 1) # for each row in val\n","print(\"done val\")\n","\n","# test set image/annotation allocation:\n","\n","images_dir_test = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/test/images\"\n","annotations_dir_test = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/test/annotations\"\n","\n","def update_filepath_test(df):\n","  # extract from df\n","    images = df[\"images\"]\n","    annotations = df[\"annotations\"]\n","\n","  # get filenames\n","    image_dest_end =  os.path.basename(images)\n","    annotations_dest_end = os.path.basename(annotations)\n","\n","  # set destination paths\n","    image_dest = os.path.join(images_dir_test, image_dest_end)\n","    annotations_dest = os.path.join(annotations_dir_test, annotations_dest_end)\n","\n","  # move to val\n","    shutil.move(images, image_dest)\n","    shutil.move(annotations, annotations_dest)\n","\n","    return pd.Series([image_dest, annotations_dest], index = [\"images\", \"annotations\"])\n","\n","\n","print(\"start test\")\n","test2 = test_df.apply(update_filepath_test, axis = 1) # for each row in test\n","print(\"end test\")\n","train2, val2, test2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733256149546,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"TpjQ9y109WEK","outputId":"8b4e9e95-777b-47ed-b190-bd864ba9984d"},"outputs":[],"source":["config = {\n","    \"nc\" : 1, # only human class (y/n binary classification)\n","    \"names\": [\"human\"],\n","    \"path\": \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format\",\n","    \"train\": \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/train\",\n","    \"val\": \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/val\",\n","    \"test\": \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/test\"\n","}\n","\n","# setup/configuration file - yaml used for YOLO model\n","\n","with open(\"config.yaml\", \"w\") as f:\n","    yaml.dump(config, f)\n","\n","with open(\"config.yaml\", \"r\") as f:\n","    print(f.read())\n","\n","config # confirming nit was correctly written"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733256150443,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"LcAeaeTjLVFn","outputId":"23282c5b-888a-4abc-922d-c65ea8a79927"},"outputs":[],"source":["path = \"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/config.yaml\"\n","print(f\"Config file created: {os.path.exists(path)}\")\n","# confirming config file exists in our YOLO-format directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6008818,"status":"ok","timestamp":1733263197670,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"DVMvhwhS9j5q","outputId":"c3db7f5f-db4f-4544-c1c5-af75882a4fce"},"outputs":[],"source":["model = YOLO(\"yolov8n.pt\") # loading pretrained model\n","\n","model.train(\n","        # defining where we will house the model-related components\n","        project=\"/content/drive/My Drive/D144/people_drone_detection_data\",\n","        name=\"yolov8n\",\n","        deterministic=True,\n","        seed=42,\n","        data=\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/config.yaml\",\n","        save=True,\n","        save_period=1,\n","        pretrained=True,\n","        imgsz=1280,\n","        epochs=5,\n","        batch=-1,\n","        workers=10,\n","        val=True,\n","        lr0=0.01,\n","        patience=3,\n","        optimizer = 'SGD',\n",") # parameters for YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":453446,"status":"ok","timestamp":1733263705365,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"uY0BO5xQiQlA","outputId":"56f2464e-9acc-4efd-e654-d61d0a526c95"},"outputs":[],"source":["metrics = model.val() # let's see how we did!\n","print(metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":472054,"status":"ok","timestamp":1733264211087,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"lsDWOAa-bts1","outputId":"d39c62cb-80b7-482c-9c82-2d257a4f4c8e"},"outputs":[],"source":["results = model.val(save=True, save_dir=\"/content/drive/My Drive/D144/people_drone_detection_data\") # save the metrics!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":548},"executionInfo":{"elapsed":818,"status":"ok","timestamp":1733294111820,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"v4h_Mumvj-oK","outputId":"afbcb9bd-82a9-4b3d-be36-390b68de26cf"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# taking our metrics csv to plot precision recall and mAP\n","metrics = pd.read_csv('/content/drive/My Drive/D144/people_drone_detection_data/results.csv')\n","\n","# plots over epochs\n","plt.figure(figsize=(14, 6))\n","\n","# precision\n","plt.subplot(1, 3, 1)\n","plt.plot(metrics['epoch'], metrics['metrics/precision(B)'], label='Precision', color='b')\n","plt.title('Precision over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Precision')\n","plt.grid(True)\n","\n","# recall\n","plt.subplot(1, 3, 2)\n","plt.plot(metrics['epoch'], metrics['metrics/recall(B)'], label='Recall', color='r')\n","plt.title('Recall over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Recall')\n","plt.grid(True)\n","\n","# mAP\n","plt.subplot(1, 3, 3)\n","plt.plot(metrics['epoch'], metrics['metrics/mAP50(B)'], label='mAP', color='g')\n","plt.title('mAP50 over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('mAP')\n","plt.grid(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":548},"executionInfo":{"elapsed":820,"status":"ok","timestamp":1733294118235,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"gPK-iQtsqPGn","outputId":"4dc1a4db-8f4d-431e-c9ee-506af40fddfd"},"outputs":[],"source":["# plotting the losses over epochs\n","plt.figure(figsize=(14, 6))\n","\n","# box loss - training\n","plt.subplot(1, 2, 1)\n","plt.plot(metrics['epoch'], metrics['train/box_loss'], label='Train Box Loss', color='b')\n","plt.title('Train Box Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Box Loss')\n","plt.grid(True)\n","\n","# box loss - validation\n","plt.subplot(1, 2, 2)\n","plt.plot(metrics['epoch'], metrics['val/box_loss'], label='Validation Box Loss', color='r')\n","plt.title('Validation Box Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Box Loss')\n","plt.grid(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2596,"status":"ok","timestamp":1733267163019,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"4Lo8if9iuCkm"},"outputs":[],"source":["model = YOLO('/content/drive/My Drive/D144/people_drone_detection_data/yolov8n3/weights/best.pt')  # reloading model after crash using best weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":192376,"status":"ok","timestamp":1733267600963,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"kd53wxt4kIay","outputId":"b840c592-6eff-4d86-d777-6f6584b23e5f"},"outputs":[],"source":["test_results = model.predict(source=\"/content/drive/My Drive/D144/people_drone_detection_data/annotation/annotation/YOLO-format/test/images\", save=True, save_dir=\"/content/drive/My Drive/D144/people_drone_detection_data\") # predicting on test set!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":12316,"status":"ok","timestamp":1733268052692,"user":{"displayName":"Akhil Venkatesh","userId":"00169604282783016550"},"user_tz":480},"id":"PU8tPn4G00iD","outputId":"1ce90de5-b38e-4fe1-ce6f-d5e9ada9a7bc"},"outputs":[],"source":["shutil.move('/content/runs/detect/predict', '/content/drive/My Drive/D144/people_drone_detection_data') # saving our predictions!"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
